{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1_data_preparation.ipynb\n",
    "\n",
    "Converts 'open-high-low-close' (OHLC) price data into a format suitable for machine learning.  Target labels are generated according to (potential) profitable trading conditions being met.  Extra data features are created, price and volume data are centralised around their moving averages, whilst time and day labels are separated out and one-hot encoded.  \n",
    "\n",
    "The working dataframe is then transformed into a tensor of dimensions [batch_size, steps, channels] by using a rolling window method.  Appropriate category labels are selected to match the last step in each window, and transformed into a tensors of dimensions [batch_size, categories]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_unix_time_into_day(seconds):\n",
    "    \"\"\" returns day of week as category label \"\"\"\n",
    "    day_of_week = time.strftime('%A', time.localtime(seconds))\n",
    "    dict = {'Saturday':1, 'Sunday':2, 'Monday':3, 'Tuesday':4, 'Wednesday':5, 'Thursday':6, 'Friday':7}\n",
    "    day_code = dict[day_of_week]\n",
    "    return day_code\n",
    "\n",
    "\n",
    "def wwma(pd_series, period):\n",
    "    \"\"\" w. wilder's EMA \"\"\"\n",
    "    return pd_series.ewm(alpha=1/period, adjust=False, ignore_na=True).mean()\n",
    "\n",
    "\n",
    "def atr(df, length=14):\n",
    "    \"\"\" average true range (for column with latest values at top) \"\"\"\n",
    "    df_high, df_low, df_prev_close = df['high'], df['low'], df['close'].shift()\n",
    "    df_tr = [df_high- df_low, df_high - df_prev_close, df_low - df_prev_close]\n",
    "    df_tr = [tr.abs() for tr in df_tr]\n",
    "    df_tr = pd.concat(df_tr, axis=1).max(axis=1)\n",
    "    df_atr = wwma(df_tr, length)\n",
    "    return df_atr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering\n",
    "Extracts learnable features from raw data, and creates and categorical labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering constants\n",
    "SMA_PERIOD = 50\n",
    "SMA_PERIOD_FAST = 20\n",
    "ATR_MULT = 0.25 \n",
    "HI_LO_WINDOW = 40\n",
    "\n",
    "# load price data into dataframe and reorder to recent = last\n",
    "df = pd.read_csv('data/OHLC_1h.csv', header=0, sep=',')\n",
    "df = df.sort_index(ascending=False, ignore_index=True)\n",
    "\n",
    "# calculate average true range and add as column to dataframe\n",
    "df_atr = atr(df)\n",
    "df['ATR'] = df_atr\n",
    "\n",
    "# create target labels \n",
    "y_labels =[]\n",
    "\n",
    "for i in range(2,len(df)):\n",
    "\n",
    "    # up condition: (high or high[1] > high[2] + spread) and (low and low[1] > low[2] + spread) \n",
    "    if (\n",
    "        ( df.loc[i, 'high'] > (df.loc[i-2, 'high'] + ATR_MULT * df.loc[i, 'ATR'])  or  \n",
    "        df.loc[i-1, 'high'] > (df.loc[i-2, 'high'] + ATR_MULT * df.loc[i, 'ATR']) )  and \n",
    "        ( df.loc[i, 'low'] > (df.loc[i-2, 'low'] + ATR_MULT * df.loc[i, 'ATR'])  and  \n",
    "        df.loc[i-1, 'low'] > (df.loc[i-2, 'low'] + ATR_MULT * df.loc[i, 'ATR']) )\n",
    "    ):\n",
    "        label = 'up'\n",
    "\n",
    "    # down condition: (low or low[1] < low[2] - spread) and (high and high[1] < high[2] - spread)\n",
    "    elif (\n",
    "        ( df.loc[i, 'low'] < (df.loc[i-2, 'low'] - ATR_MULT * df.loc[i, 'ATR'])  or  \n",
    "          df.loc[i-1, 'low'] < (df.loc[i-2, 'low'] - ATR_MULT * df.loc[i, 'ATR']) )  and \n",
    "        ( df.loc[i, 'high'] < (df.loc[i-2, 'high'] - ATR_MULT * df.loc[i, 'ATR'])  and  \n",
    "          df.loc[i-1, 'high'] < (df.loc[i-2, 'high'] - ATR_MULT * df.loc[i, 'ATR']) )\n",
    "        ):\n",
    "        label = 'down'\n",
    "    \n",
    "    else:\n",
    "        label = 'flat'\n",
    "\n",
    "    y_labels.append(label)\n",
    "\n",
    "y_labels.extend([float('NaN'), float('NaN')])\n",
    "\n",
    "# add labels to new dataframe column\n",
    "df['target'] = y_labels\n",
    "\n",
    "\n",
    "# calculate simple moving averages of closing price\n",
    "df[f'SMA_{SMA_PERIOD}'] = df['close'].rolling(SMA_PERIOD).mean()\n",
    "df[f'SMA_{SMA_PERIOD_FAST}'] = df['close'].rolling(SMA_PERIOD_FAST).mean()\n",
    "\n",
    "# calculate simple moving averages of volume\n",
    "df[f'vol SMA_{SMA_PERIOD}'] = df['volume USD'].rolling(SMA_PERIOD).mean()\n",
    "df[f'vol SMA_{SMA_PERIOD_FAST}'] = df['volume USD'].rolling(SMA_PERIOD_FAST).mean()\n",
    "\n",
    "# centralise price and volume data around relevant slower SMA\n",
    "df['open_'] = (df['open'] - df[f'SMA_{SMA_PERIOD}']) / df[f'SMA_{SMA_PERIOD}']\n",
    "df['high_'] = (df['high'] - df[f'SMA_{SMA_PERIOD}']) / df[f'SMA_{SMA_PERIOD}']\n",
    "df['low_'] = (df['low'] - df[f'SMA_{SMA_PERIOD}']) / df[f'SMA_{SMA_PERIOD}']\n",
    "df['close_'] = (df['close'] - df[f'SMA_{SMA_PERIOD}']) / df[f'SMA_{SMA_PERIOD}']\n",
    "df['vol_'] = (df['volume USD'] - df[f'vol SMA_{SMA_PERIOD}']) / df[f'vol SMA_{SMA_PERIOD}']\n",
    "\n",
    "# centralise price and volume data around relevant faster SMA\n",
    "df['close_f'] = (df['close'] - df[f'SMA_{SMA_PERIOD_FAST}']) / df[f'SMA_{SMA_PERIOD_FAST}']\n",
    "df['vol_f'] = (df['volume USD'] - df[f'vol SMA_{SMA_PERIOD_FAST}']) / df[f'vol SMA_{SMA_PERIOD_FAST}']\n",
    "\n",
    "# calculate highest high and lowest low in the last 'HI_LO_WINDOW' prices\n",
    "df[f'HH_{HI_LO_WINDOW}'] = df['high'].rolling(HI_LO_WINDOW).max().shift()\n",
    "df[f'LL_{HI_LO_WINDOW}'] = df['low'].rolling(HI_LO_WINDOW).min().shift()\n",
    "\n",
    "# centralise close price around highest high and lowest low \n",
    "df['chh_'] = (df['close'] - df[f'HH_{HI_LO_WINDOW}']) / df[f'HH_{HI_LO_WINDOW}']\n",
    "df['cll_'] = (df[f'LL_{HI_LO_WINDOW}'] - df['close']) / df[f'HH_{HI_LO_WINDOW}']\n",
    "\n",
    "# create day and hour categories\n",
    "df['day'] = df['unix'].map(lambda _: convert_unix_time_into_day(_))\n",
    "df['hour'] = df['date'].str.slice(start=11, stop=13).apply(pd.to_numeric) + 1\n",
    "\n",
    "# drop rows containing NaNs   \n",
    "df = df.dropna(axis=0)\n",
    "\n",
    "\n",
    "# create separate dataframe for one-hot encoded day/hour categories\n",
    "df_time = df[['day', 'hour']].copy()\n",
    "df_time = pd.get_dummies(df_time, columns=['day', 'hour'])\n",
    "\n",
    "# create separate dataframe for one-hot encoded target categories\n",
    "df_ylabels = df['target'].copy()\n",
    "df_ylabels = pd.get_dummies(df_ylabels, columns=['target'])\n",
    "\n",
    "# tidy up price data\n",
    "df = df.drop(columns=['unix', 'date', 'volume USD', 'volume', \n",
    "                      'open', 'high', 'low', 'close', \n",
    "                      f'SMA_{SMA_PERIOD}', f'SMA_{SMA_PERIOD_FAST}', \n",
    "                      f'vol SMA_{SMA_PERIOD}', f'vol SMA_{SMA_PERIOD_FAST}', \n",
    "                      'day', 'hour', 'target', 'ATR', \n",
    "                      f'HH_{HI_LO_WINDOW}', f'LL_{HI_LO_WINDOW}'], axis=1)\n",
    "\n",
    "# check dataframes\n",
    "print(df.head(), '\\n', len(df))\n",
    "print(df_time.head(), '\\n', len(df_time))\n",
    "print(df_ylabels.head(), '\\n', len(df_ylabels))\n",
    "\n",
    "# check data balance\n",
    "print(df_ylabels.sum(axis=0))\n",
    "print('mean:', df.stack().mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "Slices dataframe into many discrete classification problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data preparation constants\n",
    "PRICE_CHANNELS = 9\n",
    "WINDOW = 24\n",
    "STEP = 2\n",
    "\n",
    "# create numpy arrays to receive data\n",
    "price_series_data = np.zeros(shape=(WINDOW, PRICE_CHANNELS))\n",
    "time_cat_data = np.zeros(shape=(1, 31))\n",
    "target_cat_data = np.zeros(shape=(1, 3))\n",
    "\n",
    "batch_size = (len(df)-WINDOW) // STEP\n",
    "\n",
    "# iterate through price dataframe concatenating discrete arrays of size 'WINDOW', and spacing 'STEP'\n",
    "for i in range(batch_size): \n",
    "    arr = df.iloc[[(i*STEP)+j for j in range(WINDOW)], [k for k in range(PRICE_CHANNELS)]].to_numpy()\n",
    "    price_series_data = np.concatenate((price_series_data, arr))\n",
    "\n",
    "# iterate through categorical dataframes concatenating data relating to bottom row of each price window\n",
    "for i in range(batch_size): \n",
    "\n",
    "    arr = df_time.iloc[[(i*STEP) + WINDOW], : ].to_numpy()\n",
    "    time_cat_data = np.concatenate((time_cat_data, arr))\n",
    "    \n",
    "    arr = df_ylabels.iloc[[(i*STEP) + WINDOW], : ].to_numpy()\n",
    "    target_cat_data = np.concatenate((target_cat_data, arr))\n",
    "\n",
    "# reshape arrays\n",
    "price_series_data = np.reshape(price_series_data, (batch_size+1, WINDOW, PRICE_CHANNELS))\n",
    "time_cat_data = np.reshape(time_cat_data, (batch_size+1, 31))\n",
    "target_cat_data = np.reshape(target_cat_data, (batch_size+1, 3))\n",
    "\n",
    "# delete intial 'zeros' array elements\n",
    "price_series_data = np.delete(price_series_data, 0, axis=0)\n",
    "time_cat_data = np.delete(time_cat_data, 0, axis=0)\n",
    "target_cat_data = np.delete(target_cat_data, 0, axis=0)\n",
    "\n",
    "# check arrays\n",
    "print(price_series_data, price_series_data.shape)\n",
    "print(time_cat_data, time_cat_data.shape)\n",
    "print(target_cat_data, target_cat_data.shape)\n",
    "\n",
    "# save data\n",
    "with open('data/all_data.pkl', 'wb') as file:\n",
    "    pickle.dump((price_series_data, time_cat_data, target_cat_data), file, protocol=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## check negative numbers don't affect convolution..\n",
    "## true standardisation required? - does volume have similar scale/std.dev to price data?\n",
    "## add commission level to 'flat' calculation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
