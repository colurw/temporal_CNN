{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2_train_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import concatenate\n",
    "from keras.utils import plot_model\n",
    "from keras import regularizers\n",
    "from keras import losses\n",
    "from keras import callbacks\n",
    "from keras import metrics\n",
    "import keras\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import precision_recall_curve"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open('data/all_data.pkl', 'rb') as file:\n",
    "    price_series, time_categories, up_targets, dn_targets = pickle.load(file) \n",
    "\n",
    "timesteps = price_series.shape[1]\n",
    "channels = price_series.shape[2]\n",
    "time_dim = time_categories.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 7\n",
    "TARGETS = up_targets\n",
    "\n",
    "# Splitting the arrays into train and test sets\n",
    "train_x_price, test_x_price = train_test_split(price_series, test_size=0.2, random_state=RANDOM_SEED)\n",
    "train_x_time, test_x_time = train_test_split(time_categories, test_size=0.2, random_state=RANDOM_SEED)\n",
    "train_y, test_y = train_test_split(TARGETS, test_size=0.2, random_state=RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Multimodal Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILTERS = 256\n",
    "\n",
    "keras.utils.set_random_seed(7)\n",
    "\n",
    "# convolutional branch\n",
    "input_cnn = Input(shape=(timesteps,channels)) \n",
    "\n",
    "cnn = Conv1D(filters=FILTERS, kernel_size=7, padding='same', \n",
    "             activation='relu', data_format='channels_last',\n",
    "             activity_regularizer=None,\n",
    "             input_shape=(timesteps, channels))(input_cnn)\n",
    "\n",
    "cnn = Conv1D(filters=FILTERS, kernel_size=3, padding='same', \n",
    "             activation='relu', data_format='channels_last', \n",
    "             activity_regularizer=None)(cnn)\n",
    "\n",
    "cnn = Conv1D(filters=FILTERS, kernel_size=2, padding='same', strides=2,      # pooling layer\n",
    "             activation='relu', use_bias=False, data_format='channels_last', \n",
    "             activity_regularizer=None)(cnn)\n",
    "\n",
    "cnn = Conv1D(filters=FILTERS*2, kernel_size=3, padding='same', \n",
    "             activation='relu', data_format='channels_last', \n",
    "             activity_regularizer=None)(cnn)\n",
    "\n",
    "cnn = Conv1D(filters=FILTERS*2, kernel_size=2, padding='same', strides=2,     # pooling layer\n",
    "             activation='relu', use_bias=False, data_format='channels_last',\n",
    "             activity_regularizer=None)(cnn)\n",
    "\n",
    "cnn = Conv1D(filters=FILTERS*4, kernel_size=3, padding='same', \n",
    "             activation='relu', data_format='channels_last', \n",
    "             activity_regularizer=regularizers.L2(0.01))(cnn)\n",
    "\n",
    "cnn = Dropout(0.4)(cnn)\n",
    "cnn = Flatten()(cnn)\n",
    "cnn = Model(inputs=input_cnn, outputs=cnn)\n",
    "\n",
    "# perceptron branch\n",
    "input_mlp = Input(shape=(time_dim,))\n",
    "mlp = Dense(8, activation='relu', \n",
    "            activity_regularizer=regularizers.L2(0.01))(input_mlp)\n",
    "mlp = Model(inputs=input_mlp, outputs=mlp)\n",
    "\n",
    "# join branches\n",
    "combined = concatenate([cnn.output, mlp.output])\n",
    "head = Dense(1024, activation='relu')(combined)\n",
    "head = Dense(512, activation='relu')(head)\n",
    "head = Dense(2, activation='softmax')(head)\n",
    "model = Model(inputs=[cnn.input, mlp.input], outputs=head)\n",
    "\n",
    "model.compile(loss='binary_focal_crossentropy', \n",
    "              optimizer='adam', \n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "plot_model(model, to_file='model_plot.png', \n",
    "                  show_shapes=True, \n",
    "                  show_layer_names=True, \n",
    "                  show_layer_activations=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train And Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "\n",
    "callback = keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "   \t\t\t\t \t\t\t\t\t \t patience=2,\n",
    "    \t\t\t \t\t\t\t\t  \t verbose=0,\n",
    "\t\t\t\t \t\t\t\t\t\t restore_best_weights=True,)\n",
    "\n",
    "model.fit(x=[train_x_price, train_x_time], y=train_y,\n",
    "\t      validation_data=([test_x_price, test_x_time], test_y),\n",
    "\t      epochs=20, batch_size=BATCH_SIZE, callbacks=callback)\n",
    "\n",
    "loss, accuracy = model.evaluate([test_x_price, test_x_time], test_y, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(loss, accuracy)\n",
    "\n",
    "model.save('models/up/cnn3.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Precision-Recall Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model('models/up/cnn.keras')\n",
    "\n",
    "labels = model.predict([test_x_price, test_x_time])\n",
    "# keep probabilities for the positive outcome only\n",
    "probs = labels[:, 1]\n",
    "print('probs:',probs)\n",
    "\n",
    "print('labels:',labels)\n",
    "y_true = test_y[:, 0]\n",
    "print('test_y',test_y)   ### test_y allows [0. 0.] elements - fix first!\n",
    "print('y_true:',y_true)\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_true, probs)\n",
    "\n",
    "# plot the precision-recall curves\n",
    "no_skill = len(test_y[test_y==1]) / len(test_y)\n",
    "plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill')\n",
    "plt.plot(recall, precision, marker='.', label='CNN_up')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add cross validation\n",
    "## pad - most recent edge is important! #\n",
    "## replace maxpooling with dilated kernel to preserve data - geoff hinton #\n",
    "## replace maxpooling with stride = 2 - 'learnable pooling, all-convolution network' #\n",
    "## batch norm on conv layers? #\n",
    "## groups = channels maintains depthwise separation.  Add same multiple of filters?\n",
    "## l2 less sensitive to small changes (noise), l1 blocks some inputs #\n",
    "## layers.DepthwiseConv1D() reduces number of parameters\n",
    "## model.train(sample_weight=) heavier recent samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
