{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2_train_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Conv1D\n",
    "from keras.layers import MaxPooling1D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import concatenate\n",
    "from keras.utils import plot_model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "with open('data/all_data.pkl', 'rb') as file:\n",
    "    price_series_data, time_cat_data, target_cat_data = pickle.load(file) \n",
    "\n",
    "# test inputs\n",
    "train_x = np.random.rand(1,40,5)\n",
    "train_y = np.random.rand(1,3)\n",
    "\n",
    "timesteps = train_x.shape[1]\n",
    "channels = train_x.shape[2]\n",
    "\n",
    "input_cnn = Input(shape=(40,5,))\n",
    "input_mlp = Input(shape=(31,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Multimodal Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convolutional branch\n",
    "cnn = Conv1D(filters=64, padding='same', kernel_size=3, dilation_rate=1, \n",
    "                 activation='relu', data_format='channels_last',\n",
    "                 kernel_regularizer=None, bias_regularizer=None,\n",
    "                 input_shape=(timesteps, channels))(input_cnn)\n",
    "\n",
    "cnn = Conv1D(filters=64, padding='same', kernel_size=3, dilation_rate=1, \n",
    "                 activation='relu', data_format='channels_last', \n",
    "                 kernel_regularizer=None, bias_regularizer=None)(cnn)\n",
    "\n",
    "cnn = Dropout(0.0)(cnn)\n",
    "cnn = MaxPooling1D(pool_size=2, padding='same')(cnn)\n",
    "cnn = Flatten()(cnn)\n",
    "cnn = Model(inputs=input_cnn, outputs=cnn)\n",
    "\n",
    "# perceptron branch\n",
    "mlp = Dense(8, activation='relu')(input_mlp)\n",
    "mlp = Model(inputs=input_mlp, outputs=mlp)\n",
    "\n",
    "# join branches\n",
    "combined = concatenate([cnn.output, mlp.output])\n",
    "head = Dense(256, activation='relu')(combined)\n",
    "head = Dense(64, activation='relu')(head)\n",
    "head = Dense(3, activation='softmax')(head)\n",
    "model = Model(inputs=[cnn.input, mlp.input], outputs=head)\n",
    "\n",
    "#model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train And Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "batch_size = 32\n",
    "\n",
    "# fit network\n",
    "model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, verbose=False)\n",
    "# evaluate model\n",
    "_, accuracy = model.evaluate(testX, testy, batch_size=batch_size, verbose=0)\n",
    "print(accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## cross validation - KFold() sci-kitlearn\n",
    "## pad - most recent edge is important!\n",
    "## replace maxpooling with dilated kernel to preserve data - geoff hinton\n",
    "## replace maxpooling with stride = 2 - 'learnable pooling, all-convolution network'\n",
    "## batch norm on conv layers?\n",
    "## groups = channels maintains depthwise separation.  Add same multiple of filters?\n",
    "## tf.data.shuffle()\n",
    "## l2 less sensitive to small changes (noise), l1 blocks some inputs\n",
    "## layers.DepthwiseConv1D() reduces number of parameters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
